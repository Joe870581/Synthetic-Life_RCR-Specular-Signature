
'use server';
/**
 * @fileOverview AI-powered content moderation for the kids' social zone.
 *
 * - moderateKidsContent - Moderates content created by children in the social zone.
 * - ModerateKidsContentInput - The input type for the moderateKidsContent function.
 * - ModerateKidsContentOutput - The return type for the moderateKidsContent function.
 */

import {ai} from '@/ai/genkit-client';
import {z} from 'genkit';

const ModerateKidsContentInputSchema = z.object({
  content: z
    .string()
    .describe('The text content to be moderated, e.g., a social media post.'),
  mediaUrl: z
    .string()
    .optional()
    .describe(
      'The URL of the media content (image or video) to be moderated, if applicable.'
    ),
});
export type ModerateKidsContentInput = z.infer<typeof ModerateKidsContentInputSchema>;

const ModerateKidsContentOutputSchema = z.object({
  isAppropriate: z
    .boolean()
    .describe(
      'Whether the content is appropriate for children. True if safe, false if not.'
    ),
  reason: z
    .string()
    .optional()
    .describe(
      'The reason why the content was flagged as inappropriate, if applicable.'
    ),
});
export type ModerateKidsContentOutput = z.infer<typeof ModerateKidsContentOutputSchema>;

export async function moderateKidsContent(
  input: ModerateKidsContentInput
): Promise<ModerateKidsContentOutput> {
  return moderateKidsContentFlow(input);
}

const moderateKidsContentPrompt = ai.definePrompt({
  name: 'moderateKidsContentPrompt',
  input: {schema: ModerateKidsContentInputSchema},
  output: {schema: ModerateKidsContentOutputSchema},
  prompt: `You are an AI content moderation expert specializing in identifying inappropriate content for children.

You will receive content generated by children in a social zone, and your job is to determine if the content is appropriate for children.

Consider factors like:
- Profanity and offensive language
- Sexually suggestive content
- Violence and harmful acts
- Cyberbullying and harassment
- Sharing of personal information

Content: {{{content}}}
{{#if mediaUrl}}
Media URL: {{media url=mediaUrl}}
{{/if}}

Based on your analysis, set the isAppropriate output field to true if the content is safe for children, and false if it is not. If the content is not appropriate, provide a reason in the reason output field.

Ensure that the outputted JSON is valid.`,
});

const moderateKidsContentFlow = ai.defineFlow(
  {
    name: 'moderateKidsContentFlow',
    inputSchema: ModerateKidsContentInputSchema,
    outputSchema: ModerateKidsContentOutputSchema,
  },
  async input => {
    const {output} = await moderateKidsContentPrompt(input);
    return output!;
  }
);
